{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a706076d",
   "metadata": {},
   "source": [
    "\n",
    "# Marketing Campaigns — EDA & Hypothesis Testing\n",
    "\n",
    "This notebook explores the **Marketing Mix (5 Ps)** in the provided dataset: **People, Product, Place, Promotion,** (and we treat **Price** implicitly via spending). We will clean the data, engineer features, visualize patterns, and test hypotheses about customer acquisition and channel preferences.\n",
    "\n",
    "**Data files used:**\n",
    "- `marketing_data.csv` (customer-level features & outcomes)\n",
    "- `Data Dictionary - Response to marketing campaigns.xlsx` (column descriptions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50841f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Plot settings\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set(color_codes=True)\n",
    "%matplotlib inline\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 120)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed129ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load raw data\n",
    "raw_path = 'marketing_data.csv'\n",
    "df = pd.read_csv(raw_path)\n",
    "print(f\"Rows: {df.shape[0]}, Columns: {df.shape[1]}\")\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90896724",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 5.1 Clean Income: remove currency formatting and convert to float\n",
    "if ' Income ' in df.columns:\n",
    "    df.rename(columns={' Income ': 'Income'}, inplace=True)\n",
    "\n",
    "# Remove $ and commas, strip spaces; convert missing to NaN\n",
    "def _to_float(x):\n",
    "    if pd.isna(x):\n",
    "        return np.nan\n",
    "    if isinstance(x, (int, float)):\n",
    "        return float(x)\n",
    "    x = str(x).strip().replace('$', '').replace(',', '')\n",
    "    try:\n",
    "        return float(x)\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "if 'Income' in df.columns:\n",
    "    df['Income'] = df['Income'].apply(_to_float)\n",
    "\n",
    "# 5.2 Standardize categorical values in Education & Marital_Status\n",
    "# Normalize whitespace & case\n",
    "for col in ['Education', 'Marital_Status', 'Country']:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].astype(str).str.strip()\n",
    "\n",
    "# Fix rare/erroneous categories\n",
    "edu_map = {\n",
    "    'Basic': 'Basic',\n",
    "    '2n Cycle': '2n Cycle',\n",
    "    'Graduation': 'Graduation',\n",
    "    'Master': 'Master',\n",
    "    'PhD': 'PhD'\n",
    "}\n",
    "# Map anything else to closest valid (fallback to original where already valid)\n",
    "df['Education'] = df['Education'].replace({'YOLO': 'Graduation', 'Absurd': 'Graduation'})\n",
    "df.loc[~df['Education'].isin(edu_map.keys()), 'Education'] = df.loc[~df['Education'].isin(edu_map.keys()), 'Education'].apply(lambda x: 'Graduation' if x not in edu_map else x)\n",
    "\n",
    "marital_map = {\n",
    "    'Single': 'Single',\n",
    "    'Married': 'Married',\n",
    "    'Together': 'Together',\n",
    "    'Divorced': 'Divorced',\n",
    "    'Widow': 'Widow'\n",
    "}\n",
    "df['Marital_Status'] = df['Marital_Status'].replace({'Alone': 'Single', 'YOLO': 'Single'})\n",
    "df.loc[~df['Marital_Status'].isin(marital_map.keys()), 'Marital_Status'] = 'Single'\n",
    "\n",
    "# 5.3 Parse Dt_Customer and engineer Age, Children, Total Spend, Total Purchases\n",
    "\n",
    "if 'Dt_Customer' in df.columns:\n",
    "    df['Dt_Customer'] = pd.to_datetime(\n",
    "        df['Dt_Customer'].astype(str).str.strip(),\n",
    "        format='%m/%d/%y',\n",
    "        errors='coerce'\n",
    "    )\n",
    "\n",
    "# Age: use year at enrollment if available else assume 2014 (dataset horizon)\n",
    "reference_year = 2014\n",
    "if 'Year_Birth' in df.columns:\n",
    "    df['Age'] = np.where(df['Dt_Customer'].notna(), df['Dt_Customer'].dt.year - df['Year_Birth'], reference_year - df['Year_Birth'])\n",
    "\n",
    "# Children total\n",
    "df['Children'] = df[['Kidhome', 'Teenhome']].sum(axis=1)\n",
    "\n",
    "# Total spend across products\n",
    "spend_cols = ['MntWines','MntFruits','MntMeatProducts','MntFishProducts','MntSweetProducts','MntGoldProds']\n",
    "spend_cols = [c for c in spend_cols if c in df.columns]\n",
    "df['Total_Spend'] = df[spend_cols].sum(axis=1)\n",
    "\n",
    "# Total purchases across channels\n",
    "purchase_cols = ['NumWebPurchases','NumCatalogPurchases','NumStorePurchases']\n",
    "purchase_cols = [c for c in purchase_cols if c in df.columns]\n",
    "df['Total_Purchases'] = df[purchase_cols].sum(axis=1)\n",
    "\n",
    "# 5.4 Handle outliers: cap (winsorize) Age, Income, Total_Spend at 1st/99th percentiles\n",
    "for c in ['Age','Income','Total_Spend']:\n",
    "    if c in df.columns:\n",
    "        lower, upper = df[c].quantile([0.01, 0.99])\n",
    "        df[c] = df[c].clip(lower, upper)\n",
    "\n",
    "# 5.5 Impute missing Income grouped by Education & Marital_Status (median within group)\n",
    "if 'Income' in df.columns:\n",
    "    df['Income'] = df.groupby(['Education','Marital_Status'])['Income'].transform(lambda s: s.fillna(s.median()))\n",
    "\n",
    "# 5.6 Ordinal encode Education\n",
    "education_order = ['Basic','2n Cycle','Graduation','Master','PhD']\n",
    "df['Education_Ord'] = pd.Categorical(df['Education'], categories=education_order, ordered=True).codes\n",
    "\n",
    "# Preview cleaned data\n",
    "df[['ID','Year_Birth','Age','Education','Education_Ord','Marital_Status','Income','Children','Total_Spend','Total_Purchases']].head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91cd9755",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- EDA Visualizations ---\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "sns.histplot(df['Age'], kde=True, ax=axes[0,0], color='steelblue')\n",
    "axes[0,0].set_title('Age Distribution')\n",
    "\n",
    "sns.histplot(df['Income'], kde=True, ax=axes[0,1], color='darkgreen')\n",
    "axes[0,1].set_title('Income Distribution')\n",
    "\n",
    "sns.histplot(df['Total_Spend'], kde=True, ax=axes[1,0], color='purple')\n",
    "axes[1,0].set_title('Total Spend Distribution')\n",
    "\n",
    "sns.histplot(df['Total_Purchases'], kde=True, ax=axes[1,1], color='orange')\n",
    "axes[1,1].set_title('Total Purchases Distribution')\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Boxplot: Income by Education\n",
    "plt.figure(figsize=(10,5))\n",
    "sns.boxplot(x='Education', y='Income', data=df, order=['Basic','2n Cycle','Graduation','Master','PhD'])\n",
    "plt.title('Income by Education Level')\n",
    "plt.xticks(rotation=0)\n",
    "plt.show()\n",
    "\n",
    "# Correlation heatmap\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns\n",
    "plt.figure(figsize=(12,9))\n",
    "sns.heatmap(df[numeric_cols].corr(), cmap='coolwarm', center=0)\n",
    "plt.title('Correlation Heatmap (Numeric Features)')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec35acc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Hypothesis Testing ---\n",
    "results = {}\n",
    "\n",
    "# H1: Older individuals prefer in-store shopping (vs online)\n",
    "# Define older as Age >= median\n",
    "age_median = df['Age'].median()\n",
    "df['AgeGroup'] = np.where(df['Age'] >= age_median, 'Older', 'Younger')\n",
    "\n",
    "older_store = df.loc[df['AgeGroup']=='Older', 'NumStorePurchases']\n",
    "younger_store = df.loc[df['AgeGroup']=='Younger', 'NumStorePurchases']\n",
    "\n",
    "older_web = df.loc[df['AgeGroup']=='Older', 'NumWebPurchases']\n",
    "younger_web = df.loc[df['AgeGroup']=='Younger', 'NumWebPurchases']\n",
    "\n",
    "# t-tests\n",
    "t_store = stats.ttest_ind(older_store.dropna(), younger_store.dropna(), equal_var=False)\n",
    "t_web = stats.ttest_ind(older_web.dropna(), younger_web.dropna(), equal_var=False)\n",
    "\n",
    "results['H1_store_pref'] = {'t_stat': t_store.statistic, 'p_value': t_store.pvalue}\n",
    "results['H1_web_pref_inverse'] = {'t_stat': t_web.statistic, 'p_value': t_web.pvalue}\n",
    "\n",
    "# H2: Customers with children shop more online\n",
    "with_children = df.loc[df['Children']>0, 'NumWebPurchases']\n",
    "no_children = df.loc[df['Children']==0, 'NumWebPurchases']\n",
    "t_children = stats.ttest_ind(with_children.dropna(), no_children.dropna(), equal_var=False)\n",
    "results['H2_children_online'] = {'t_stat': t_children.statistic, 'p_value': t_children.pvalue}\n",
    "\n",
    "# H3: Cannibalization: store purchases negatively correlate with online+catalog\n",
    "omni = df[['NumStorePurchases','NumWebPurchases','NumCatalogPurchases']].dropna()\n",
    "omni['NonStore'] = omni['NumWebPurchases'] + omni['NumCatalogPurchases']\n",
    "rho, pval = stats.pearsonr(omni['NumStorePurchases'], omni['NonStore'])\n",
    "results['H3_cannibalization_corr'] = {'pearson_r': rho, 'p_value': pval}\n",
    "\n",
    "# H4: US vs Rest in Total Purchases\n",
    "if 'Country' in df.columns:\n",
    "    us = df.loc[df['Country']=='US', 'Total_Purchases']\n",
    "    rest = df.loc[df['Country']!='US', 'Total_Purchases']\n",
    "    t_us = stats.ttest_ind(us.dropna(), rest.dropna(), equal_var=False)\n",
    "    results['H4_US_vs_Rest_total_purchases'] = {'t_stat': t_us.statistic, 'p_value': t_us.pvalue,\n",
    "                                               'US_mean': float(us.mean()), 'Rest_mean': float(rest.mean()),\n",
    "                                               'US_n': int(us.count()), 'Rest_n': int(rest.count())}\n",
    "\n",
    "# Show results\n",
    "import pprint\n",
    "pprint.pprint(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478bb75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Business Insights & Visuals ---\n",
    "\n",
    "# Top-performing products by total revenue\n",
    "product_totals = df[spend_cols].sum().sort_values(ascending=False)\n",
    "plt.figure(figsize=(9,5))\n",
    "\n",
    "\n",
    "product_df = product_totals.reset_index()\n",
    "product_df.columns = ['Product', 'Total']\n",
    "\n",
    "sns.barplot(\n",
    "    data=product_df,\n",
    "    x='Product', y='Total',\n",
    "    hue='Product',                 # assign hue\n",
    "    palette='viridis',\n",
    "    legend=False                   # same visual effect, no legend\n",
    ")\n",
    "\n",
    "plt.title('Total Revenue by Product Category (2 years)')\n",
    "plt.ylabel('Total Amount')\n",
    "plt.xlabel('Product')\n",
    "plt.xticks(rotation=35)\n",
    "plt.show()\n",
    "\n",
    "# Acceptance rate of last campaign vs age bands\n",
    "df['AgeBand'] = pd.cut(df['Age'], bins=[0,30,40,50,60,100], labels=['<30','30-39','40-49','50-59','60+'])\n",
    "acc_rate_by_age = df.groupby('AgeBand', observed=True)['Response'].mean()\n",
    "plt.figure(figsize=(8,4))\n",
    "sns.barplot(x=acc_rate_by_age.index.astype(str), y=acc_rate_by_age.values, color='teal')\n",
    "plt.title('Last Campaign Acceptance Rate by Age Band')\n",
    "plt.ylabel('Acceptance Rate')\n",
    "plt.xlabel('Age Band')\n",
    "plt.show()\n",
    "\n",
    "# Country with highest number of customers who accepted last campaign\n",
    "acc_by_country = df.loc[df['Response']==1].groupby('Country')['ID'].count().sort_values(ascending=False)\n",
    "plt.figure(figsize=(10,5))\n",
    "sns.barplot(x=acc_by_country.index, y=acc_by_country.values, color='slateblue')\n",
    "plt.title('Accepted Last Campaign — Customers by Country')\n",
    "plt.ylabel('Count of Customers')\n",
    "plt.xlabel('Country')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n",
    "\n",
    "# Pattern: children vs total expenditure\n",
    "plt.figure(figsize=(8,4))\n",
    "sns.boxplot(x='Children', y='Total_Spend', data=df)\n",
    "plt.title('Total Spend vs Number of Children at Home')\n",
    "plt.xlabel('Children at Home')\n",
    "plt.ylabel('Total Spend (2 years)')\n",
    "plt.show()\n",
    "\n",
    "# Education of customers who complained in last 2 years\n",
    "complaints = df.loc[df['Complain']==1]\n",
    "complaints_edu = complaints['Education'].value_counts()\n",
    "plt.figure(figsize=(8,4))\n",
    "sns.barplot(x=complaints_edu.index, y=complaints_edu.values, color='crimson')\n",
    "plt.title('Complaints by Education Level (last 2 years)')\n",
    "plt.xlabel('Education Level')\n",
    "plt.ylabel('Count of Complaints')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a402da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# --- Encoding Examples ---\n",
    "\n",
    "# Ordinal encoding already applied for Education (Education_Ord)\n",
    "\n",
    "# One-hot for Marital_Status & Country (examples)\n",
    "cat_cols = []\n",
    "for c in ['Marital_Status','Country']:\n",
    "    if c in df.columns:\n",
    "        cat_cols.append(c)\n",
    "\n",
    "if cat_cols:\n",
    "    ohe = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "    ohe_df = pd.DataFrame(ohe.fit_transform(df[cat_cols]))\n",
    "    ohe_df.columns = ohe.get_feature_names_out(cat_cols)\n",
    "    encoded_df = pd.concat([df.drop(columns=cat_cols), ohe_df], axis=1)\n",
    "    encoded_df.head()\n",
    "else:\n",
    "    print(\"No categorical columns available for one-hot encoding demo.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0df540",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Save cleaned dataset for downstream work\n",
    "out_path = 'marketing_data_cleaned.csv'\n",
    "df.to_csv(out_path, index=False)\n",
    "print(f\"Cleaned dataset written to {out_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
